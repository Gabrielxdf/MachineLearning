{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrielxdf/MachineLearning/blob/main/SBERT_FINE_TUNNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence_transformers"
      ],
      "metadata": {
        "id": "KeULfD8UDufD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtDagDquepkw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer, InputExample, models, evaluation, losses, util\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk9UkiZOepkz"
      },
      "source": [
        "# Obtendo os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm9pfreM4zRc"
      },
      "outputs": [],
      "source": [
        "url = 'https://drive.google.com/file/d/1Wxc14dsJdUqOGFdauRs-Adw1Hy5Y3fEU/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfDCYyNKepk1"
      },
      "outputs": [],
      "source": [
        "# Lendo e salvando para CSV\n",
        "def obter_dados_csv():\n",
        "    df_dados = pd.read_csv(url)\n",
        "    df_dados.to_csv('dados.csv', index=False, encoding='utf-8')\n",
        "    return df_dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H29f1WGtepk1"
      },
      "outputs": [],
      "source": [
        "df_dados = obter_dados_csv()\n",
        "df_dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eORVfEdaepk3"
      },
      "source": [
        "# Removendo os dígitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqTq1uckepk3"
      },
      "outputs": [],
      "source": [
        "df_dados[\"curriculos\"] = df_dados[\"curriculos\"].apply(lambda x: re.sub('\\d+', '', x))\n",
        "df_dados[\"vagas\"] = df_dados[\"vagas\"].apply(lambda x: re.sub('\\d+', '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfIgWYF9epk4"
      },
      "outputs": [],
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaler.set_output(transform='pandas');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_ibJ6406egZ"
      },
      "outputs": [],
      "source": [
        "df_dados[\"notas\"] = min_max_scaler.fit_transform(df_dados[\"notas\"].values.reshape(-1, 1))\n",
        "# 1 -> 0.00\n",
        "# 2 -> 0.25\n",
        "# 3 -> 0.50\n",
        "# 4 -> 0.75\n",
        "# 5 -> 1.00\n",
        "df_dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0NJZ-fMepk4"
      },
      "source": [
        "# Preparando os dados para treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVb7iHfVepk5"
      },
      "outputs": [],
      "source": [
        "data_examples = []\n",
        "for index, row in df_dados.iterrows():\n",
        "    data_examples.append(InputExample(texts=[row['curriculos'], row['vagas']], label=row['notas']))\n",
        "\n",
        "# Dividindo os dados em 80% treino, 20% validação e 20% para testes\n",
        "data_examples = shuffle(data_examples, random_state=42)\n",
        "indice_treino = int(len(data_examples) * 0.6)\n",
        "indice_val = int(len(data_examples) * 0.2)\n",
        "\n",
        "train_examples = data_examples[:indice_treino]\n",
        "val_examples = data_examples[indice_treino:indice_treino+indice_val]\n",
        "test_examples = data_examples[indice_treino+indice_val:]\n",
        "\n",
        "# Criando os Dataloaders do PyTorch\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Vn_P-Qepk5"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECYP6Kh-epk6"
      },
      "outputs": [],
      "source": [
        "checkpoint = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "\n",
        "word_embedding_model = models.Transformer(checkpoint)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "\n",
        "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name='sbert')\n",
        "\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=5, evaluator=evaluator, show_progress_bar=True, save_best_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09EhnkpwcQ9i"
      },
      "source": [
        "# Testando um sistema de recomendação de vagas para um currículo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_curriculo = 'Nome: Laura Costa - Objetivo: Busco uma posição como Analista Econômico, onde posso aplicar minha formação acadêmica em Economia e aprimorar minhas habilidades em análise econômica. Formação Acadêmica: Bacharelado em Economia - Universidade Federal de Estado Y (-) Experiência Profissional: Assistente de Análise Econômica - Empresa de Consultoria Econômica LTDA - Cidade Financeira, Estado Y (-Presente) Coleta de dados econômicos. Auxílio na elaboração de relatórios e análises. Habilidades: Conhecimentos intermediários em análise econômica. Familiaridade com ferramentas como Excel e SPSS. Idiomas: Inglês: Avançado Espanhol: Básico'\n",
        "test_vagas = list(set([test_example.texts[1] for test_example in test_examples]))"
      ],
      "metadata": {
        "id": "cj6zNQJPgLi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk_0VThQchBF"
      },
      "outputs": [],
      "source": [
        "embedding_curriculo = model.encode(test_curriculo)\n",
        "embedding_vagas = [model.encode(vaga) for vaga in test_vagas]\n",
        "scores_similaridade = util.cos_sim(embedding_curriculo, embedding_vagas)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrando os pares curriculo-vaga com as maiores similaridades de cosseno\n",
        "pares = []\n",
        "for index, score in enumerate(scores_similaridade[0]):\n",
        "    pares.append({\"index\": index, \"score\": score})\n",
        "\n",
        "# Ordena os pares pelos scores na ordem decrescente\n",
        "pares = sorted(pares, key=lambda x: x[\"score\"], reverse=True)"
      ],
      "metadata": {
        "id": "-S_0ajIZcp31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNptEnBb0wwy"
      },
      "outputs": [],
      "source": [
        "print(f' Currículo: {test_curriculo} \\n\\n')\n",
        "for par in pares[0:5]:\n",
        "    print(f' Vaga: {test_vagas[par[\"index\"]]} \\n Similaridade predita após o ajuste fino: {par[\"score\"]} \\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}